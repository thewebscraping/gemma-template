{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Gemma Template","text":"<p>This library was developed for the Kaggle challenge: Google - Unlocking Global Communication with Gemma, sponsored by Google.</p>"},{"location":"#credit-requirement","title":"Credit Requirement","text":"<p>Important: If you are a participant in the competition and wish to use this source code in your submission, you must clearly credit the original author before the competition's end date, January 14, 2025.</p> <p>Please include the following information in your submission:</p> <pre><code>Author: Tu Pham\nKaggle Username: [bigfishdev](https://www.kaggle.com/bigfishdev)\nGitHub: [https://github.com/thewebscraping/gemma-template/](https://github.com/thewebscraping/gemma-template)\nLinkedIn: [https://www.linkedin.com/in/thetwofarm](https://www.linkedin.com/in/thetwofarm)\n</code></pre>"},{"location":"#overview","title":"Overview","text":"<p>Gemma Template is a lightweight and efficient Python library for generating templates to fine-tune models and craft prompts. Designed for flexibility, it seamlessly supports Gemma, LLaMA, and other language frameworks, offering fast, user-friendly customization. With multilingual capabilities and advanced configuration options, it ensures precise, professional, and dynamic template creation.</p>"},{"location":"#learning-process-and-acknowledgements","title":"Learning Process and Acknowledgements","text":"<p>As a newbie, I created Gemma Template based on what I read and learned from the following sources:</p> <ul> <li>Google Gemma Cookbook: Advanced Prompting Techniques</li> <li>Google Gemma Cookbook: Finetune with LLaMA Factory</li> <li>Google Gemma Cookbook: Fine tuning Gemma for Function Calling</li> <li>Alpaca: Alpaca Lora Documentation</li> <li>Unsloth: Finetune Llama 3.2, Mistral, Phi-3.5, Qwen 2.5 &amp; Gemma 2-5x faster with 80% less memory!</li> </ul> <p>Gemma Template supports exporting dataset files in three formats: <code>Text</code>, <code>Alpaca</code>, and <code>OpenAI</code>.</p>"},{"location":"#multilingual-content-writing-assistant","title":"Multilingual Content Writing Assistant","text":"<p>This writing assistant is a multilingual professional writer specializing in crafting structured, engaging, and SEO-optimized content. It enhances text readability, aligns with linguistic nuances, and preserves original context across various languages.</p>"},{"location":"#key-features","title":"Key Features:","text":""},{"location":"#1-creative-and-engaging-rewrites","title":"1. Creative and Engaging Rewrites","text":"<ul> <li>Transforms input text into captivating and reader-friendly content.</li> <li>Utilizes vivid imagery and descriptive language to enhance engagement.</li> </ul>"},{"location":"#2-advanced-text-analysis","title":"2. Advanced Text Analysis","text":"<ul> <li>Processes text with unigrams, bigrams, and trigrams to understand linguistic patterns.</li> <li>Ensures language-specific nuances and cultural integrity are preserved.</li> </ul>"},{"location":"#3-seo-optimized-responses","title":"3. SEO-Optimized Responses","text":"<ul> <li>Incorporates keywords naturally to improve search engine visibility.</li> <li>Aligns rewritten content with SEO best practices for discoverability.</li> </ul>"},{"location":"#4-professional-and-multilingual-expertise","title":"4. Professional and Multilingual Expertise","text":"<ul> <li>Full support for creating templates in local languages.</li> <li>Supports multiple languages with advanced prompting techniques.</li> <li>Vocabulary and grammar enhancement with unigrams, bigrams, and trigrams instruction template.</li> <li>Supports hidden mask input text. Adapts tone and style to maintain professionalism and clarity.</li> <li>Full documentation with easy configuration prompts and examples.</li> </ul>"},{"location":"#5-customize-advanced-response-structure-and-dataset-format","title":"5. Customize Advanced Response Structure and Dataset Format","text":"<ul> <li>Supports advanced response structure format customization.</li> <li>Compatible with other models such as LLaMa.</li> <li>Enhances dynamic prompts using Round-Robin loops.</li> <li>Outputs multiple formats such as Text, Alpaca and OpenAI.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install the library, you can choose between two methods:</p>"},{"location":"#1-install-via-pypi","title":"1. Install via PyPI:","text":"<pre><code>pip install gemma-template\n</code></pre>"},{"location":"#2-install-via-github-repository","title":"2. Install via GitHub Repository:","text":"<pre><code>pip install git+https://github.com/thewebscraping/gemma-template.git\n</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Start using Gemma Template with just a few lines of code:</p>"},{"location":"#load-dataset","title":"Load Dataset","text":"<p>Returns: A Hugging Face Dataset or DatasetDict object containing the processed prompts.</p>"},{"location":"#load-dataset-from-data-dict","title":"Load Dataset from data dict","text":"<pre><code>from gemma_template import gemma_template\n\ndata_dict = [\n    {\n        \"id\": \"JnZJolR76_u2\",\n        \"title\": \"Sample title\",\n        \"description\": \"Sample description\",\n        \"document\": \"Sample document\",\n        \"categories\": [\"Topic 1\", \"Topic 2\"],\n        \"tags\": [\"Tag 1\", \"Tag 2\"],\n        \"output\": \"Sample output\",\n        \"main_points\": [\"Main point 1\", \"Main point 2\"],\n    }\n]\ndataset = gemma_template.load_dataset(data_dict, output_format='text')   # enum: `text`, `alpaca` and `openai`.\nprint(dataset['text'][0])\n</code></pre>"},{"location":"#load-dataset-from-local-file-path-or-huggingface-dataset","title":"Load Dataset from local file path or HuggingFace dataset","text":"<pre><code>from gemma_template import gemma_template\n\ndataset = gemma_template.load_dataset(\n    \"YOUR_JSON_FILE_PATH_OR_HUGGINGFACE_DATASET\",\n    # enum: `text`, `alpaca` and `openai`.\n    output_format='text',\n    # Percentage of documents that need to be word masked.\n    # Min: 0, Max: 1. Default: 0.\n    max_hidden_ratio=.1,\n    # Replace 10% of words in the input document with '_____'.\n    # Use int to extract the correct number of words. The `max_hidden_ratio` parameter must be greater than 0.\n    max_hidden_words=.1,\n    # Minimum character of a word, used to create unigrams, bigrams, and trigrams. Default is 2.\n    min_chars_length=2,\n    # Maximum character of a word, used to create unigrams, bigrams and trigrams. Default is 0.\n    max_chars_length=8,\n)\n</code></pre>"},{"location":"#fully-customized-template","title":"Fully Customized Template","text":"<pre><code>from gemma_template import Template, FieldPosition, INPUT_TEMPLATE, OUTPUT_TEMPLATE, INSTRUCTION_TEMPLATE, PROMPT_TEMPLATE\n\ntemplate_instance = Template(\n    instruction_template=[INSTRUCTION_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    prompt_template=[PROMPT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    input_template=[INPUT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    output_template=[OUTPUT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    position=FieldPosition(\n            title=[\"Custom Title\"],\n            description=[\"Custom Description\"],\n            document=[\"Custom Article\"],\n            main_points=[\"Custom Main Points\"],\n            categories=[\"Custom Categories\"],\n            tags=[\"Custom Tags\"],\n    ),  # Optional: dynamic Round-Robin loops\n)\n\nresponse = template_instance.apply_template(\n    title=\"Gemma open models\",\n    description=\"Gemma: Introducing new state-of-the-art open models.\",\n    main_points=[\"Main point 1\", \"Main point 2\"],\n    categories=[\"Artificial Intelligence\", \"Gemma\"],\n    tags=[\"AI\", \"LLM\", \"Google\"],\n    document=\"Gemma open models are built from the same research and technology as Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.\",\n    output=\"A new family of open language models demonstrating strong performance across academic benchmarks for language understanding, reasoning, and safety.\",\n    max_hidden_words=.1,  # set 0 if you don't want to hide words.\n    min_chars_length=2,  # Minimum character of a word, used to create unigrams, bigrams, and trigrams. Default is 2.\n    max_chars_length=0,  # Maximum character of a word, used to create unigrams, bigrams and trigrams. Default is 0.\n)  # remove kwargs if not used.\n\nprint(response)\n</code></pre>"},{"location":"#output","title":"Output","text":"<pre><code>&lt;start_of_turn&gt;user\nYou are a multilingual professional writer.\n\n# Role:\nYou are a highly skilled professional content writer, linguistic analyst, and multilingual expert specializing in structured writing and advanced text processing.\n\n# Task:\nYour primary objectives are:\n1. Simplification: Rewrite the input text or document to ensure it is accessible and easy to understand for a general audience while preserving the original meaning and essential details.\n2. Lexical and Grammatical Analysis: Analyze and refine vocabulary and grammar using unigrams (single words), bigrams (two words), and trigrams (three words) to enhance readability and depth.\n3. Structure and Organization: Ensure your response adheres strictly to the prescribed structure format.\n4. Language Consistency: Respond in the same language as the input text unless explicitly directed otherwise.\n\n# Additional Guidelines:\n1. Provide a rewritten, enhanced version of the input text, ensuring professionalism, clarity, and improved structure.\n2. Focus on multilingual proficiency, using complex vocabulary, grammar to improve your responses.\n3. Preserve the context and cultural nuances of the original text when rewriting.\n\n# Text Analysis:\nExample 1: Unigrams (single words)\nand =&gt; English\nbuilt =&gt; English\nfrom =&gt; English\nthe =&gt; English\nresearch =&gt; English\nText Analysis 3: These are common English words, indicating the text is in English.\n\nExample 2: Bigrams (two words)\ntechnology as =&gt; English\nText Analysis 2: Frequent bigrams in English confirm the language context.\n\nExample 3: Trigrams (three words)\ntechnology as Gemini =&gt; English\nText Analysis 3: Trigrams further validate the linguistic analysis and the necessity to respond in English.\n\n# Conclusion of Text Analysis:\nThe linguistic analysis confirms the text is predominantly in English. Consequently, the response should be structured and written in English to align with the original text and context.\n\n# Input Text:\nRewrite the input text or document to highlight its unique value proposition while ensuring it ranks well for targeted keywords.\n\n# Response Structure Format:\nYou must follow the response structure:\n\n**Custom Title (Title):** Rewrite the title to maximize clarity, appeal, and relevance to the content.\n**Custom Description (Description):** Create a description focusing on how the article addresses a common problem or challenge readers face.\n**Custom Article (Article):** Rewrite the input text or document with an authoritative tone, incorporating credible sources, data, and references to boost trustworthiness and SEO ranking.\n**Custom Main Points (Main Points):** Ensure all key points flow logically from one to the next.\n**Custom Categories (Categories):** Use categories that align with similar articles on the topic and improve SEO and discoverability.\n**Custom Tags (Tags):** Rewrite tags to make them more specific and targeted.\n\nBy adhering to this format, the response will maintain linguistic integrity while enhancing professionalism, structure and alignment with user expectations.\n\n# Text:\nGemma open models are built _____ the same _____ and technology as Gemini models. Gemma 2 comes in 2B, 9B _____ 27B and Gemma 1 comes in 2B and 7B sizes.&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n## **Custom Title:**\n### Gemma open models\n\n## **Custom Description:**\nGemma: Introducing new state-of-the-art open models.\n\n## **Custom Article:**\nA new family of open language models demonstrating strong performance across academic benchmarks for language understanding, reasoning, and safety.\n\n## **Custom Main Points:**\n* Main point 1\n* Main point 2\n\n## **Custom Categories:**\n* Artificial Intelligence\n* Gemma\n\n## **Custom Tags:**\n* AI\n* LLM\n* Google&lt;end_of_turn&gt;\n</code></pre>"},{"location":"benchmark/","title":"Benchmark","text":""},{"location":"benchmark/#goal","title":"Goal","text":"<p>An article typically consists of the following elements: title, description, main points, categories, and tags. This fine tuning is designed to address these elements in a single request using a custom structured format. Additional objectives include:</p> <ol> <li>Enhancing the model's ability to process and respond effectively in the local language.</li> <li>Improving the structured output format for better usability.</li> </ol>"},{"location":"benchmark/#gemma-2b-evaluation-results","title":"Gemma 2B - Evaluation Results","text":"<p>The performance of the Gemma 2B model was assessed using ROUGE and Google BLEU metrics.</p> Rouge1 Rouge2 RougeL RougeLSum Google BLEU 0.722 0.524 0.456 0.703 0.345 <p>Key Observations:</p> <ul> <li> <p>The model shows significant improvements in:</p> <ul> <li>Handling user language responses.</li> <li>Structured content generation.</li> </ul> </li> <li> <p>Challenges:</p> <ul> <li>Incomplete feedback for certain articles.</li> <li>Occasional duplication of keywords in responses.</li> </ul> </li> </ul> <p>For more details, you can read version 1 of this Notebook: (Version 1). Also, you can download the file <code>gemma-benchmark/gemma_2b_eval_benchmark.json</code> which I have attached on this notebook.</p> <p>Due to Kaggle limitations, I am currently unable to implement ROUGE and Google BLEU eval evaluations on the Gemma 2B IT (Version 2) model that I have refined. I will show a demo how I eval the dataset and the source code at the end of this notebook.</p> <ul> <li>Kaggle Gemma 2B Model:<ul> <li>Model: https://www.kaggle.com/models/bigfishdev/gemma-template-gemma-2b</li> <li>Notebook Version 1: https://www.kaggle.com/code/bigfishdev/gemma-2b-it-fine-tuning-with-gemma-template?scriptVersionId=216121364</li> </ul> </li> <li>Kaggle Gemma 2B IT Model:<ul> <li>Model: https://www.kaggle.com/models/bigfishdev/gemma-template-gemma-2b-it</li> <li>Notebook Version 2: https://www.kaggle.com/code/bigfishdev/gemma-2b-it-fine-tuning-with-gemma-template?scriptVersionId=216252050</li> </ul> </li> <li>Dataset: https://www.kaggle.com/datasets/bigfishdev/gemma-template</li> <li>Benchmark: All benchmarks will be updated at my Github repo: https://github.com/thewebscraping/gemma-template/blob/main/docs/benchmark.md</li> </ul>"},{"location":"benchmark/#gemma-2b-vietnamese-vmlu-evaluation-results","title":"Gemma 2B - Vietnamese VMLU Evaluation Results","text":"<p>VMLU is a benchmark suite designed to evaluate foundational models with a focus on the Vietnamese language.</p> ID Created At Stem Social Science Humanities Others AVG Unanswered 1624257089558187281 05/01/2025 17:56 20.14 29.35 29.84 25.76 25.61 1497"},{"location":"benchmark/#results","title":"Results","text":"<ul> <li>Out of 9,834 attempts, 1,497 responses were unanswered.</li> <li>The dataset and evaluation results can be downloaded from the file: <code>gemma-benchmark/gemma_2b_vmlu_answers.csv</code>. Although it is not within the scope of this fine tuning.</li> </ul>"},{"location":"benchmark/#gemma-2b-it-vietnamese-vmlu-evaluation-results","title":"Gemma 2B IT - Vietnamese VMLU Evaluation Results","text":"ID Created At Stem Social Science Humanities Others AVG Unanswered 1840435368978448913 06/01/2025 19:04 36.11 43.45 41.92 39.06 39.64 82"},{"location":"benchmark/#results_1","title":"Results","text":"<ul> <li>Out of 9,834 attempts, 82 responses were unanswered.</li> <li>The dataset and evaluation results can be downloaded from the file: <code>gemma-benchmark/gemma_2b_it_vmlu_benchmark.csv</code>. Although it is not within the scope of this fine tuning.</li> </ul>"},{"location":"benchmark/#my-gemma-fine-tuning-vmlu-score","title":"My Gemma Fine Tuning VMLU Score","text":""},{"location":"benchmark/#vmlu-leaderboard","title":"VMLU Leaderboard","text":"<p>There is a clear difference between the VMLU rankings in the Gemma 2B IT fine tuning, the score is close to the score of the Gemma 7B IT model. Here is a screenshot of the VMLU Leaderboard rankings:</p> <p></p>"},{"location":"benchmark/#additional-resources","title":"Additional Resources","text":"<ul> <li>VMLU Website: https://vmlu.ai/</li> <li>VMLU Leaderboard: https://vmlu.ai/leaderboard</li> <li>VMLU Github Repository: https://github.com/ZaloAI-Jaist/VMLU/</li> </ul>"},{"location":"generate_methods/","title":"Generate Methods","text":"<pre><code>&gt;&gt;&gt; from gemma_template import Template, gemma_template\n&gt;&gt;&gt; isinstance(gemma_template, Template)\nTrue\n</code></pre> <p>See also: Method Arguments</p>"},{"location":"generate_methods/#generate-user-prompt","title":"Generate User Prompt","text":"<p>Create user prompt for Gemma Fine tuning.</p> <p>See also: Method Arguments</p> <p>Parameters</p> <ul> <li>max_hidden_words (Union[int, float]): default <code>0</code>.<ul> <li>Replace words in the document with '_____'.</li> <li><code>int</code>: exact number of words to be masked.</li> <li><code>float</code>: percentage of number of words to be masked.</li> </ul> </li> <li>min_chars_length (int): default <code>2</code>.<ul> <li>Minimum character of a word, used to create unigrams, bigrams, and trigrams. Default is 2.</li> </ul> </li> <li>max_chars_length (int): default <code>0</code>.<ul> <li>Maximum character of a word, used to create unigrams, bigrams and trigrams. Default is 0.</li> </ul> </li> <li>bullet_style (enum): default <code>asterisk</code><ul> <li>Create Markdown style bulleted list <code>asterisk</code>, <code>dash</code>, <code>number</code>.</li> </ul> </li> </ul> <pre><code>&gt;&gt;&gt; prompt = gemma_template.generate_user_prompt(\n...     document='This is a Test!',\n...     description='Test description',\n...     categories=['Example 1', 'Example 2'],\n...     tags=['Tag 1', 'Tag 2'], output='Test'\n... )\n'''\nYou are a multilingual professional writer.\n\n# Role:\nYou are a highly skilled professional content writer, linguistic analyst, and multilingual expert specializing in structured writing and advanced text processing.\n\n# Task:\nYour primary objectives are:\n1. Simplification: Rewrite the input text or document to ensure it is accessible and easy to understand for a general audience while preserving the original meaning and essential details.\n2. Lexical and Grammatical Analysis: Analyze and refine vocabulary and grammar using unigrams (single words), bigrams (two words), and trigrams (three words) to enhance readability and depth.\n3. Structure and Organization: Ensure your response adheres strictly to the prescribed structure format.\n4. Language Consistency: Respond in the same language as the input text unless explicitly directed otherwise.\n\n# Additional Guidelines:\n1. Provide a rewritten, enhanced version of the input text, ensuring professionalism, clarity, and improved structure.\n2. Focus on multilingual proficiency, using complex vocabulary, grammar to improve your responses.\n3. Preserve the context and cultural nuances of the original text when rewriting.\n\n# Text Analysis:\nExample 1: Unigrams (single words)\nThis =&gt; English\nText Analysis 3: These are common English words, indicating the text is in English.\n\nExample 2: Bigrams (two words)\nis a =&gt; English\na Test =&gt; English\nText Analysis 2: Frequent bigrams in English confirm the language context.\n\nExample 3: Trigrams (three words)\nis a Test =&gt; English\nText Analysis 3: Trigrams further validate the linguistic analysis and the necessity to respond in English.\n\n# Conclusion of Text Analysis:\nThe linguistic analysis confirms the text is predominantly in English. Consequently, the response should be structured and written in English to align with the original text and context.\n\n# Input Text:\nRewrite the input text or document to make it more persuasive and compelling. Focus on strengthening arguments, appealing to emotions, and using rhetorical techniques to convince the reader.\n\n# Response Structure Format:\nYou must follow the response structure:\n\n**Meta Description:** Begin the description with a thought-provoking question to spark curiosity and encourage clicks.\n**Edit Article:** Rewrite the input text or document to make it simpler and easier to understand for a general audience. Use clear and concise language while preserving the original meaning and key details.\n**Topics:** Rewrite categories to match keywords used in the article.\n**Keywords:** Rewrite tags to include relevant keywords in about 5 keywords.\n\nBy adhering to this format, the response will maintain linguistic integrity while enhancing professionalism, structure and alignment with user expectations.\n\n# Text:\nThis is a Test!\n'''\n</code></pre>"},{"location":"generate_methods/#masked-hidden-text","title":"Masked Hidden Text","text":"<pre><code>&gt;&gt;&gt; prompt = gemma_template.generate_user_prompt(\n...     document='Gemma open models are built from the same research and technology as Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.',\n...     max_hidden_words=0.1,\n...     min_chars_length=2,\n... )\n'''\nYou are a multilingual professional writer.\n...\n\n# Text:\nGemma open models are built from _____ same _____ and technology _____ Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.\n'''\n</code></pre>"},{"location":"generate_methods/#generate-model-prompt","title":"Generate Model Prompt","text":"<p>Create model prompt for Gemma Fine tuning.</p> <p>See also: Method Arguments</p> <pre><code>&gt;&gt;&gt; prompt = gemma_template.generate_model_prompt(\n...     document='This is a Test!',\n...     description='Test description',\n...     categories=['Example 1', 'Example 2'],\n...     tags=['Tag 1', 'Tag 2'], output='Test'\n... )\n\n'''## **Introduction:**\nTest description\n\n## **Article:**\nTest\n\n## **Categories:**\n* Example 1\n* Example 2\n\n## **Tags:**\n* Tag 1\n* Tag 2\n'''\n</code></pre>"},{"location":"generate_methods/#generate-prompt-for-question","title":"Generate Prompt for Question","text":"<p>Quickly create question prompts using the Gemma model.</p> <p>See also: Method Arguments</p> <pre><code>&gt;&gt;&gt; prompt = gemma_template.generate_prompt(document='This is a Test!')\n'''\n&lt;start_of_turn&gt;user\nYou are a multilingual professional writer.\n\n# Role:\nYou are a highly skilled professional content writer, linguistic analyst, and multilingual expert specializing in structured writing and advanced text processing.\n\n# Task:\nYour primary objectives are:\n1. Simplification: Rewrite the input text or document to ensure it is accessible and easy to understand for a general audience while preserving the original meaning and essential details.\n2. Lexical and Grammatical Analysis: Analyze and refine vocabulary and grammar using unigrams (single words), bigrams (two words), and trigrams (three words) to enhance readability and depth.\n3. Structure and Organization: Ensure your response adheres strictly to the prescribed structure format.\n4. Language Consistency: Respond in the same language as the input text unless explicitly directed otherwise.\n\n# Additional Guidelines:\n1. Provide a rewritten, enhanced version of the input text, ensuring professionalism, clarity, and improved structure.\n2. Focus on multilingual proficiency, using complex vocabulary, grammar to improve your responses.\n3. Preserve the context and cultural nuances of the original text when rewriting.\n\n# Text Analysis:\nExample 1: Unigrams (single words)\nThis =&gt; English\nText Analysis 3: These are common English words, indicating the text is in English.\n\nExample 2: Bigrams (two words)\nis a =&gt; English\na Test =&gt; English\nText Analysis 2: Frequent bigrams in English confirm the language context.\n\nExample 3: Trigrams (three words)\nis a Test =&gt; English\nText Analysis 3: Trigrams further validate the linguistic analysis and the necessity to respond in English.\n\n# Conclusion of Text Analysis:\nThe linguistic analysis confirms the text is predominantly in English. Consequently, the response should be structured and written in English to align with the original text and context.\n\n# Input Text:\nReimagine the input text or document with a more engaging and creative tone. Add  metaphors, analogies, or storytelling elements to make it more captivating for readers.\n\n# Response Structure Format:\nYou must follow the response structure:\n\n**Article:** Reimagine the input text or document with a more engaging and creative tone. Add  metaphors, analogies, or storytelling elements to make it more captivating for readers.\n\nBy adhering to this format, the response will maintain linguistic integrity while enhancing professionalism, structure and alignment with user expectations.\n\n# Text:\nThis is a Test!\n&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n'''\n</code></pre>"},{"location":"load_dataset/","title":"Load Dataset","text":"<p>Processes and loads a dataset, generating prompts based on the provided templates. This function supports various input formats such as file paths, dictionaries, or Hugging Face Dataset objects. It uses templates to create structured prompts and supports concurrent processing for efficiency.</p>"},{"location":"load_dataset/#parameters","title":"Parameters","text":""},{"location":"load_dataset/#sample-data","title":"Sample data","text":"<pre><code>data_dict = [\n    {\n        \"id\": \"JnZJolR76_u2\",\n        \"title\": \"Gemma open models\",\n        \"description\": \"Gemma: Introducing new state-of-the-art open models\",\n        \"document\": \"Gemma open models are built from the same research and technology as Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.\",\n        \"categories\": [\"Topic 1\", \"Topic 2\"],\n        \"tags\": [\"Tag 1\", \"Tag 2\"],\n        \"output\": \"Sample output\",\n        \"main_points\": [\"Main point 1\", \"Main point 2\"],\n    },\n    {\n        \"id\": \"JnZJolR76_u2\",\n        \"title\": \"Gemma open models\",\n        \"description\": \"Gemma: Introducing new state-of-the-art open models\",\n        \"document\": \"Gemma open models are built from the same research and technology as Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.\",\n        \"categories\": [\"Topic 1\", \"Topic 2\"],\n        \"tags\": [\"Tag 1\", \"Tag 2\"],\n        \"output\": \"Sample output\",\n        \"main_points\": [\"Main point 1\", \"Main point 2\"],\n    },\n]\n</code></pre>"},{"location":"load_dataset/#text-dataset","title":"Text Dataset","text":"<p>Generate Text dataset Format</p> <pre><code>&gt;&gt;&gt; from gemma_template import gemma_template\n&gt;&gt;&gt; dataset = gemma_template.load_dataset(data_dict, output_format='text')\n&gt;&gt;&gt; dataset\nDataset({\n    features: ['text', 'analysis', 'is_masked', 'origin_data'],\n    num_rows: 2\n})\n&gt;&gt;&gt; dataset[0]\n{\n    'text': '&lt;start_of_turn&gt;user\\nYou are...&lt;end_of_turn&gt;\\n&lt;start_of_turn&gt;model\\n## **Title:**...&lt;end_of_turn&gt;\\n',\n    'analysis': {'bigrams': ['technology as'],\n    'keyword_value': 'Tag 1, Tag 2',\n    'language': 'English',\n    'language_code': 'en',\n    'topic_value': 'Topic 1, Topic 2',\n    'trigrams': ['technology as Gemini'],\n    'unigrams': ['and', 'built', 'from', 'the', 'research']},\n    'is_masked': False,\n    'origin_data': {}\n}\n</code></pre>"},{"location":"load_dataset/#alpaca-dataset","title":"Alpaca Dataset","text":"<p>Generate Alpaca dataset format.</p> <pre><code>&gt;&gt;&gt; from gemma_template import gemma_template\n&gt;&gt;&gt; dataset = gemma_template.load_dataset(data_dict, output_format='alpaca')\n&gt;&gt;&gt; dataset\nDataset({\n    features: ['instruction', 'input', 'output', 'analysis', 'is_masked', 'origin_data'],\n    num_rows: 2\n})\n&gt;&gt;&gt; dataset[0]\n{\n    'instruction': 'You are a multilingual professional writer...',\n    'input': '# Input Text:\\nRewrite the input text..',\n    'output': '## **Title:**\\n### Gemma open models\\n\\n## **Meta Description:**\\nGemma: Introducing new state-of-the-art open models...',\n    'analysis': {'bigrams': ['technology as'],\n    'keyword_value': 'Tag 1, Tag 2',\n    'language': 'English',\n    'language_code': 'en',\n    'topic_value': 'Topic 1, Topic 2',\n    'trigrams': ['technology as Gemini'],\n    'unigrams': ['and', 'built', 'from', 'the', 'research']},\n    'is_masked': False,\n    'origin_data': {}\n}\n</code></pre>"},{"location":"load_dataset/#openai-dataset","title":"OpenAI Dataset","text":"<p>Generate OpenAI dataset format.</p> <pre><code>&gt;&gt;&gt; from gemma_template import gemma_template\n&gt;&gt;&gt; dataset = gemma_template.load_dataset(data_dict, output_format='openai')\n&gt;&gt;&gt; dataset\nDataset({\n    features: ['messages', 'analysis', 'is_masked', 'origin_data'],\n    num_rows: 2\n})\n&gt;&gt;&gt; dataset[0]\n{\n    'messages': [\n        {\n            'content': 'You are a multilingual professional writer...',\n            'role': 'developer'\n        },\n        {\n            'content': '# Input Text:\\nRewrite the input text...',\n            'role': 'user'\n        },\n        {\n            'content': '## **Title:**\\n### Gemma open models...',\n            'role': 'assistant'\n        }\n    ],\n    'analysis': {\n        'bigrams': ['technology as'],\n        'keyword_value': 'Tag 1, Tag 2',\n        'language': 'English',\n        'language_code': 'en',\n        'topic_value': 'Topic 1, Topic 2',\n        'trigrams': ['technology as Gemini'],\n        'unigrams': ['and', 'built', 'from', 'the', 'research']\n    },\n    'is_masked': False,\n    'origin_data': {}\n}\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>This class is inspired by advanced natural language processing needs and optimized for use with open models like Gemma.</p>"},{"location":"models/#template","title":"Template","text":"<p>The <code>Template</code> class extends the <code>BaseTemplate</code> class to provide specialized functionality for generating structured prompts. It combines system, user, and structural prompt templates to create flexible, multi-purpose content generation workflows.</p>"},{"location":"models/#attributes","title":"Attributes","text":"<ul> <li><code>template</code> (<code>list[TemplateTypes]</code>): Base template for constructing the final prompt.</li> <li><code>input_template</code> (<code>list[TemplateTypes]</code>): Template for user inputs.</li> <li><code>output_template</code> (<code>list[TemplateTypes]</code>): Template for model outputs.</li> <li><code>instruction_template</code> (<code>list[TemplateTypes]</code>): Template for instructions, if applicable.</li> <li><code>prompt_template</code> (<code>list[TemplateTypes]</code>): Template for structured prompts, if applicable.</li> <li><code>system_prompts</code> (<code>list[str]</code>): Defines the role or behavior of the model.</li> <li><code>user_prompts</code> (<code>list[str]</code>): Specifies user queries or requests.</li> <li><code>title</code> (<code>list[str]</code>): Collection of SEO-optimized titles.</li> <li><code>description</code> (<code>list[str]</code>): Compelling introductions or meta descriptions.</li> <li><code>document</code> (<code>list[str]</code>): Enhances main content.</li> <li><code>main_points</code> (<code>list[str]</code>): Summarizes or emphasizes key points.</li> <li><code>categories</code> (<code>list[str]</code>): Identifies article themes.</li> <li><code>tags</code> (<code>list[str]</code>): Enhances tags for SEO purposes.</li> <li><code>position</code> (<code>Optional[FieldPosition]</code>): Manages structured fields within the prompt.</li> </ul>"},{"location":"models/#methods","title":"Methods","text":"<ul> <li><code>load_dataset</code>: Processes and loads a dataset, generating prompts based on the provided templates. This function supports various input formats such as file paths, dictionaries, or Hugging Face Dataset objects. It uses templates to create structured prompts and supports concurrent processing for efficiency.</li> <li><code>to_text</code>: Generate Text format.</li> <li><code>to_alpaca</code>: Generate Alpaca format.</li> <li><code>to_openai</code>: Generate OpenAI format.</li> <li><code>apply_template</code>: Generates a complete prompt by integrating system, user, and structural elements.</li> <li><code>generate_prompt</code>: Generates a prompt to predict.</li> <li><code>generate_user_prompt</code>: Generates a user-specific prompt by combining multiple user-defined inputs. This method collects and formats user prompts, optionally including structural elements, to create a coherent and complete prompt.</li> <li><code>generate_model_prompt</code>: Generates a model-specific prompt by formatting output and document content according to structural rules. This method organizes output content and any additional fields into a structured format for model processing.</li> <li><code>get_template_attr</code>: Generates an kwargs for the Attr instance.</li> </ul>"},{"location":"models/#method-arguments","title":"Method Arguments","text":"<ul> <li><code>document</code> (<code>Optional[list[str]]</code>): Model input, typically the same as the article content.</li> <li><code>output</code> (<code>Optional[str]</code>): Model response output, typically the same as the document field.</li> <li><code>title</code> (<code>Optional[str]</code>): Model response output, typically the same as the title field.</li> <li><code>description</code> (<code>Optional[str]</code>): Model response output, typically the same as the description field.</li> <li><code>main_points</code> (<code>Optional[list[str]]</code>): Model response output, typically the same as the main_points field.</li> <li><code>categories</code> (<code>Optional[list[str]]</code>): Model response output, typically the same as the categories field.</li> <li><code>tags</code> (<code>Optional[list[str]]</code>): Model response output, typically the same as the tags field.</li> <li><code>excluded_fields</code> (<code>Optional[Sequence[str]]</code>): Fields excluded to response. Default is empty sequence.</li> <li><code>bullet_style</code> (<code>Optional[Literal['dash', 'number', 'asterisk']]</code>): The style of the bullet points in the prompt. Default is <code>'asterisk'</code>. Possible values:<ul> <li><code>'dash'</code>: Bullets styled with dashes (<code>-</code>).</li> <li><code>'number'</code>: Bullets styled with numbers (<code>1.</code>, <code>2.</code>, etc.).</li> <li><code>'asterisk'</code>: Bullets styled with asterisks (<code>*</code>).</li> </ul> </li> <li><code>max_hidden_words</code> (<code>Union[int, float]</code>):<ul> <li>Replace words in the document with _____.</li> <li><code>int</code>: exact number of words to be masked.</li> <li><code>float</code>: percentage of number of words to be masked.</li> </ul> </li> <li><code>min_chars_length</code> (<code>int</code>): Minimum character of a word, used to create unigrams, bigrams, and trigrams.</li> <li><code>max_chars_length</code> (<code>int</code>): Maximum character of a word, used to create unigrams, bigrams and trigrams.</li> </ul>"},{"location":"models/#fieldposition","title":"FieldPosition","text":"<p>Inherits from BaseTemplate and adds specific fields for structured data like title, description and tags.</p>"},{"location":"models/#attributes_1","title":"Attributes","text":"<ul> <li><code>title</code> (<code>list[str]</code>): List of title suggestions.</li> <li><code>description</code> (<code>list[str]</code>): List of description suggestions.</li> <li><code>document</code> (<code>list[str]</code>): List of document suggestions.</li> <li><code>main_points</code> (<code>list[str]</code>): List of main point suggestions.</li> <li><code>categories</code> (<code>list[str]</code>): List of category suggestions.</li> <li><code>tags</code> (<code>list[str]</code>): List of tag suggestions.</li> </ul>"},{"location":"models/#methods_1","title":"Methods","text":"<ul> <li><code>items</code>: Returns a list of tuples containing field information.</li> </ul>"},{"location":"models/#fieldlabel","title":"FieldLabel","text":"<p>Represents a label associated with a structured field.</p>"},{"location":"models/#attributes_2","title":"Attributes","text":"<ul> <li><code>key</code> (<code>str</code>): The identifier of the label.</li> <li><code>value</code> (<code>str</code>): The value associated with the label.</li> <li><code>default</code> (<code>str</code>): The default label name.</li> <li><code>custom</code> (<code>str</code>): A custom label name, overriding the default.</li> </ul>"},{"location":"models/#field","title":"Field","text":"<p>Represents a structured field with a key, value, and associated label.</p>"},{"location":"models/#attributes_3","title":"Attributes","text":"<ul> <li><code>key</code> (<code>str</code>): The field identifier.</li> <li><code>value</code> (<code>str</code>): The field value.</li> <li> </li> </ul>"},{"location":"models/#label-fieldlabel-an-instance-of-fieldlabel-providing-metadata","title":"<code>label</code> (<code>FieldLabel</code>): An instance of <code>FieldLabel</code> providing metadata.","text":""},{"location":"models/#analysis","title":"Analysis","text":"<p>Holds detailed analysis-related metadata.</p>"},{"location":"models/#attributes_4","title":"Attributes:","text":"<ul> <li><code>language</code> (<code>Optional[str]</code>): The language of the content.</li> <li><code>language_code</code> (<code>Optional[str]</code>): The code representing the language.</li> <li><code>unigrams</code>, <code>bigrams</code>, <code>trigrams</code> (<code>Optional[Sequence[str]]</code>): Lists of unigrams, bigrams, and trigrams.</li> <li><code>topic_value</code> (<code>Optional[str]</code>): The topic's computed value.</li> <li><code>keyword_value</code> (<code>Optional[str]</code>): The keyword's computed value.</li> </ul>"},{"location":"models/#attr","title":"Attr","text":"<p>Defines attributes for prompts and their metadata.</p>"},{"location":"models/#attributes_5","title":"Attributes","text":"<ul> <li><code>system_prompt</code> (<code>Optional[str]</code>): Defines the system prompt.</li> <li><code>prompt</code> (<code>Optional[str]</code>): The core prompt content.</li> <li><code>prompt_structure</code> (<code>Optional[str]</code>): A template or structure for the prompt.</li> <li><code>instruction</code> (<code>Optional[str]</code>): Instructions for generating the prompt.</li> <li><code>structure_fields</code> (<code>List[Field]</code>): A list of <code>Field</code> objects representing structured fields.</li> <li><code>input</code> (<code>Optional[str]</code>): The input provided to the system.</li> <li><code>output</code> (<code>Optional[str]</code>): The system's output.</li> <li><code>analysis</code> (<code>Optional[Analysis]</code>): An <code>Analysis</code> object for content metadata.</li> <li><code>is_masked</code> (<code>Optional[bool]</code>): Whether masking is applied to the prompt.</li> </ul>"},{"location":"quickstart/","title":"Quickstart Guide","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<p>To install the library, you can choose between two methods:</p>"},{"location":"quickstart/#1-install-via-pypi","title":"1. Install via PyPI:","text":"<pre><code>pip install gemma-template\n</code></pre>"},{"location":"quickstart/#2-install-via-github-repository","title":"2. Install via GitHub Repository:","text":"<pre><code>pip install git+https://github.com/thewebscraping/gemma-template.git\n</code></pre>"},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<p>Start using Gemma Template with just a few lines of code:</p>"},{"location":"quickstart/#load-dataset","title":"Load Dataset","text":"<p>Returns: A Hugging Face Dataset or DatasetDict object containing the processed prompts.</p>"},{"location":"quickstart/#load-dataset-from-data-dict","title":"Load Dataset from data dict","text":"<pre><code>from gemma_template import gemma_template\n\ndata_dict = [\n    {\n        \"id\": \"JnZJolR76_u2\",\n        \"title\": \"Sample title\",\n        \"description\": \"Sample description\",\n        \"document\": \"Sample document\",\n        \"categories\": [\"Topic 1\", \"Topic 2\"],\n        \"tags\": [\"Tag 1\", \"Tag 2\"],\n        \"output\": \"Sample output\",\n        \"main_points\": [\"Main point 1\", \"Main point 2\"],\n    }\n]\ndataset = gemma_template.load_dataset(data_dict, output_format='text')   # enum: `text`, `alpaca` and `openai`.\nprint(dataset['text'][0])\n</code></pre>"},{"location":"quickstart/#load-dataset-from-local-file-path-or-huggingface-dataset","title":"Load Dataset from local file path or HuggingFace dataset","text":"<pre><code>from gemma_template import gemma_template\n\ndataset = gemma_template.load_dataset(\n    \"YOUR_JSON_FILE_PATH_OR_HUGGINGFACE_DATASET\",\n    # enum: `text`, `alpaca` and `openai`.\n    output_format='text',\n    # Percentage of documents that need to be word masked.\n    # Min: 0, Max: 1. Default: 0.\n    max_hidden_ratio=.1,\n    # Replace 10% of words in the input document with '_____'.\n    # Use int to extract the correct number of words. The `max_hidden_ratio` parameter must be greater than 0.\n    max_hidden_words=.1,\n    # Minimum character of a word, used to create unigrams, bigrams, and trigrams. Default is 2.\n    min_chars_length=2,\n    # Maximum character of a word, used to create unigrams, bigrams and trigrams. Default is 0.\n    max_chars_length=8,\n)\n</code></pre>"},{"location":"quickstart/#fully-customized-template","title":"Fully Customized Template","text":"<pre><code>from gemma_template import Template, FieldPosition, INPUT_TEMPLATE, OUTPUT_TEMPLATE, INSTRUCTION_TEMPLATE, PROMPT_TEMPLATE\n\ntemplate_instance = Template(\n    instruction_template=[INSTRUCTION_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    prompt_template=[PROMPT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    input_template=[INPUT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    output_template=[OUTPUT_TEMPLATE],  # Optional: dynamic Round-Robin loops\n    position=FieldPosition(\n            title=[\"Custom Title\"],\n            description=[\"Custom Description\"],\n            document=[\"Custom Article\"],\n            main_points=[\"Custom Main Points\"],\n            categories=[\"Custom Categories\"],\n            tags=[\"Custom Tags\"],\n    ),  # Optional: dynamic Round-Robin loops\n)\n\nresponse = template_instance.apply_template(\n    title=\"Gemma open models\",\n    description=\"Gemma: Introducing new state-of-the-art open models.\",\n    main_points=[\"Main point 1\", \"Main point 2\"],\n    categories=[\"Artificial Intelligence\", \"Gemma\"],\n    tags=[\"AI\", \"LLM\", \"Google\"],\n    document=\"Gemma open models are built from the same research and technology as Gemini models. Gemma 2 comes in 2B, 9B and 27B and Gemma 1 comes in 2B and 7B sizes.\",\n    output=\"A new family of open language models demonstrating strong performance across academic benchmarks for language understanding, reasoning, and safety.\",\n    max_hidden_words=.1,  # set 0 if you don't want to hide words.\n    min_chars_length=2,  # Minimum character of a word, used to create unigrams, bigrams, and trigrams. Default is 2.\n    max_chars_length=0,  # Maximum character of a word, used to create unigrams, bigrams and trigrams. Default is 0.\n)  # remove kwargs if not used.\n\nprint(response)\n</code></pre>"},{"location":"quickstart/#output","title":"Output","text":"<pre><code>&lt;start_of_turn&gt;user\nYou are a multilingual professional writer.\n\n# Role:\nYou are a highly skilled professional content writer, linguistic analyst, and multilingual expert specializing in structured writing and advanced text processing.\n\n# Task:\nYour primary objectives are:\n1. Simplification: Rewrite the input text or document to ensure it is accessible and easy to understand for a general audience while preserving the original meaning and essential details.\n2. Lexical and Grammatical Analysis: Analyze and refine vocabulary and grammar using unigrams (single words), bigrams (two words), and trigrams (three words) to enhance readability and depth.\n3. Structure and Organization: Ensure your response adheres strictly to the prescribed structure format.\n4. Language Consistency: Respond in the same language as the input text unless explicitly directed otherwise.\n\n# Additional Guidelines:\n1. Provide a rewritten, enhanced version of the input text, ensuring professionalism, clarity, and improved structure.\n2. Focus on multilingual proficiency, using complex vocabulary, grammar to improve your responses.\n3. Preserve the context and cultural nuances of the original text when rewriting.\n\n# Text Analysis:\nExample 1: Unigrams (single words)\nand =&gt; English\nbuilt =&gt; English\nfrom =&gt; English\nthe =&gt; English\nresearch =&gt; English\nText Analysis 3: These are common English words, indicating the text is in English.\n\nExample 2: Bigrams (two words)\ntechnology as =&gt; English\nText Analysis 2: Frequent bigrams in English confirm the language context.\n\nExample 3: Trigrams (three words)\ntechnology as Gemini =&gt; English\nText Analysis 3: Trigrams further validate the linguistic analysis and the necessity to respond in English.\n\n# Conclusion of Text Analysis:\nThe linguistic analysis confirms the text is predominantly in English. Consequently, the response should be structured and written in English to align with the original text and context.\n\n# Input Text:\nRewrite the input text or document to highlight its unique value proposition while ensuring it ranks well for targeted keywords.\n\n# Response Structure Format:\nYou must follow the response structure:\n\n**Custom Title (Title):** Rewrite the title to maximize clarity, appeal, and relevance to the content.\n**Custom Description (Description):** Create a description focusing on how the article addresses a common problem or challenge readers face.\n**Custom Article (Article):** Rewrite the input text or document with an authoritative tone, incorporating credible sources, data, and references to boost trustworthiness and SEO ranking.\n**Custom Main Points (Main Points):** Ensure all key points flow logically from one to the next.\n**Custom Categories (Categories):** Use categories that align with similar articles on the topic and improve SEO and discoverability.\n**Custom Tags (Tags):** Rewrite tags to make them more specific and targeted.\n\nBy adhering to this format, the response will maintain linguistic integrity while enhancing professionalism, structure and alignment with user expectations.\n\n# Text:\nGemma open models are built _____ the same _____ and technology as Gemini models. Gemma 2 comes in 2B, 9B _____ 27B and Gemma 1 comes in 2B and 7B sizes.&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n## **Custom Title:**\n### Gemma open models\n\n## **Custom Description:**\nGemma: Introducing new state-of-the-art open models.\n\n## **Custom Article:**\nA new family of open language models demonstrating strong performance across academic benchmarks for language understanding, reasoning, and safety.\n\n## **Custom Main Points:**\n* Main point 1\n* Main point 2\n\n## **Custom Categories:**\n* Artificial Intelligence\n* Gemma\n\n## **Custom Tags:**\n* AI\n* LLM\n* Google&lt;end_of_turn&gt;\n</code></pre>"},{"location":"quickstart/#gemma-fine-tuning","title":"Gemma Fine Tuning","text":"<p>You can see a sample Kaggle notebook here:</p> <ul> <li>Notebook: Gemma 2B IT Fine Tuning with Gemma Template on Kaggle</li> </ul>"},{"location":"custom_templates/custom_template/","title":"Custom Templates to Vietnamese Language","text":"<p>Gemma Template uses Jinja2 template.</p> <p>See also: <code>models.Attr</code></p>"},{"location":"custom_templates/custom_template/#gemma-fine-tuning-template","title":"Gemma Fine Tuning Template","text":"<pre><code>&lt;start_of_turn&gt;user\n{{ input }}&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n{{ output }}&lt;end_of_turn&gt;\n</code></pre>"},{"location":"custom_templates/custom_template/#gemma-prompt-template","title":"Gemma Prompt Template","text":"<pre><code>&lt;start_of_turn&gt;user\n{{ input }}&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n</code></pre>"},{"location":"custom_templates/custom_template/#input-template","title":"Input Template","text":"<pre><code>{{ system_prompt }}\n{% if instruction %}\\n{{ instruction }}\\n{% endif %}\n{% if prompt_structure %}{{ prompt_structure }}\\n{% else %}{{ prompt }}\\n{% endif %}\n# V\u0103n B\u1ea3n:\n{{ input }}\n{% if topic_value %}\\nDanh M\u1ee5c: {{ topic_value }}\\n{% endif %}{% if keyword_value %}T\u1eeb Kho\u00e1: {{ keyword_value }}\\n{% endif %}\n</code></pre>"},{"location":"custom_templates/custom_template/#output-template","title":"Output Template","text":"<pre><code>{% if structure_fields %}{% for field in structure_fields %}## **{{ field.label.custom or field.label.default }}:**\\n{% if field.key == 'title' %}### {% endif%}{{ field.value }}\\n\\n{% endfor %}{% else %}{{ output }}{% endif %}\n</code></pre>"},{"location":"custom_templates/custom_template/#instruction-template","title":"Instruction Template","text":"<pre><code># Vai tr\u00f2:\nB\u1ea1n l\u00e0 m\u1ed9t bi\u00ean t\u1eadp vi\u00ean n\u1ed9i dung chuy\u00ean nghi\u1ec7p, nh\u00e0 ph\u00e2n t\u00edch ng\u00f4n ng\u1eef v\u00e0 chuy\u00ean gia \u0111a ng\u00f4n ng\u1eef, chuy\u00ean v\u1ec1 vi\u1ebft c\u00f3 c\u1ea5u tr\u00fac v\u00e0 x\u1eed l\u00fd v\u0103n b\u1ea3n n\u00e2ng cao.\n\n# Nhi\u1ec7m V\u1ee5:\nM\u1ee5c ti\u00eau ch\u00ednh c\u1ee7a b\u1ea1n l\u00e0:\n1. Nhi\u1ec7m v\u1ee5 ch\u00ednh c\u1ee7a b\u1ea1n l\u00e0 vi\u1ebft l\u1ea1i n\u1ed9i dung \u0111\u01b0\u1ee3c cung c\u1ea5p theo \u0111\u1ecbnh d\u1ea1ng c\u00f3 c\u1ea5u tr\u00fac, chuy\u00ean nghi\u1ec7p h\u01a1n, \u0111\u1ed3ng th\u1eddi v\u1eabn gi\u1eef nguy\u00ean \u00fd \u0111\u1ecbnh v\u00e0 \u00fd ngh\u0129a ban \u0111\u1ea7u.\n2. N\u00e2ng cao kh\u1ea3 n\u0103ng hi\u1ec3u t\u1eeb v\u1ef1ng b\u1eb1ng c\u00e1ch ph\u00e2n t\u00edch v\u0103n b\u1ea3n v\u1edbi unigrams (t\u1eeb \u0111\u01a1n), bigrams (hai t\u1eeb) v\u00e0 trigrams (ba t\u1eeb).\n3. \u0110\u1ea3m b\u1ea3o ph\u1ea3n h\u1ed3i c\u1ee7a b\u1ea1n tu\u00e2n th\u1ee7 nghi\u00eam ng\u1eb7t \u0111\u1ecbnh d\u1ea1ng c\u1ea5u tr\u00fac \u0111\u01b0\u1ee3c quy \u0111\u1ecbnh.\n4. Ph\u1ea3n h\u1ed3i b\u1eb1ng ng\u00f4n ng\u1eef ch\u00ednh c\u1ee7a v\u0103n b\u1ea3n \u0111\u1ea7u v\u00e0o tr\u1eeb khi c\u00f3 h\u01b0\u1edbng d\u1eabn thay th\u1ebf r\u00f5 r\u00e0ng.\n\n# K\u1ef3 V\u1ecdng B\u1ed5 Sung:\n1. Cung c\u1ea5p phi\u00ean b\u1ea3n v\u0103n b\u1ea3n \u0111\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c vi\u1ebft l\u1ea1i, n\u00e2ng cao, \u0111\u1ea3m b\u1ea3o t\u00ednh chuy\u00ean nghi\u1ec7p, r\u00f5 r\u00e0ng v\u00e0 c\u1ea5u tr\u00fac \u0111\u01b0\u1ee3c c\u1ea3i thi\u1ec7n.\n2. T\u1eadp trung v\u00e0o kh\u1ea3 n\u0103ng \u0111a ng\u00f4n ng\u1eef, s\u1eed d\u1ee5ng v\u1ed1n t\u1eeb v\u1ef1ng ph\u1ee9c t\u1ea1p, ng\u1eef ph\u00e1p \u0111\u1ec3 c\u1ea3i thi\u1ec7n ph\u1ea3n h\u1ed3i c\u1ee7a b\u1ea1n.\n3. Gi\u1eef nguy\u00ean ng\u1eef c\u1ea3nh v\u00e0 s\u1eafc th\u00e1i v\u0103n h\u00f3a c\u1ee7a v\u0103n b\u1ea3n g\u1ed1c khi vi\u1ebft l\u1ea1i.\n{% if topic_value %}\\nTopics: {{ topic_value }}\\n{% endif %}{% if keyword_value %}Keywords: {{ keyword_value }}\\n{% endif %}\n\n# Ph\u00e2n T\u00edch V\u0103n B\u1ea3n:\nV\u00ed D\u1ee5 1: Unigrams (nh\u00f3m 1 ch\u1eef c\u00e1i){% for word in unigrams %}\\n{{ word }} =&gt; Ti\u1ebfng Vi\u1ec7t ({{ language }}){% endfor %}\n\nPh\u00e2n T\u00edch V\u0103n B\u1ea3n 1: \u0111\u00e2y l\u00e0 nh\u1eefng t\u1eeb th\u00f4ng d\u1ee5ng trong ti\u1ebfng Vi\u1ec7t ({{ language }}), cho bi\u1ebft v\u0103n b\u1ea3n \u0111\u01b0\u1ee3c vi\u1ebft b\u1eb1ng ti\u1ebfng Vi\u1ec7t ({{ language }}).\n\nV\u00ed D\u1ee5 2: Bigrams (nh\u00f3m 2 ch\u1eef c\u00e1i){% for word in bigrams %}\\n{{ word }} =&gt; Ti\u1ebfng Vi\u1ec7t ({{ language }}){% endfor %}\nPh\u00e2n T\u00edch V\u0103n B\u1ea3n 2: c\u00e1c t\u1eeb gh\u00e9p th\u01b0\u1eddng g\u1eb7p trong Ti\u1ebfng Vi\u1ec7t ({{ language }}) x\u00e1c nh\u1eadn b\u1ed1i c\u1ea3nh ng\u00f4n ng\u1eef.\n\nV\u00ed D\u1ee5 3: Trigrams (nh\u00f3m 3 ch\u1eef c\u00e1i)\\n{% for word in trigrams %}{{ word }} =&gt; Ti\u1ebfng Vi\u1ec7t ({{ language }}){% endfor %}\nPh\u00e2n T\u00edch V\u0103n B\u1ea3n 3: c\u00e1c t\u1eeb gh\u00e9p 3 ch\u1eef li\u00ean ti\u1ebfp l\u00e0 nh\u1eefng t\u1eeb ti\u1ebfng Vi\u1ec7t s\u1eed d\u1ee5ng th\u01b0\u1eddng xuy\u00ean, x\u00e1c nh\u1eadn s\u1ef1 c\u1ea7n thi\u1ebft ph\u1ea3i ph\u1ea3n h\u1ed3i b\u1eb1ng Ti\u1ebfng Vi\u1ec7t ({{ language }}).\n\n# K\u1ebft Lu\u1eadn Ph\u00e2n T\u00edch V\u0103n B\u1ea3n:\nPh\u00e2n t\u00edch ng\u00f4n ng\u1eef x\u00e1c nh\u1eadn v\u0103n b\u1ea3n ch\u1ee7 y\u1ebfu b\u1eb1ng Ti\u1ebfng Vi\u1ec7t ({{ language }}). Do \u0111\u00f3, ph\u1ea3n h\u1ed3i ph\u1ea3i \u0111\u01b0\u1ee3c c\u1ea5u tr\u00fac v\u00e0 vi\u1ebft b\u1eb1ng Ti\u1ebfng Vi\u1ec7t ({{ language }}). \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi v\u0103n b\u1ea3n v\u00e0 ng\u1eef c\u1ea3nh g\u1ed1c.\n</code></pre>"},{"location":"custom_templates/custom_template/#prompt-template","title":"Prompt Template","text":"<pre><code>{% if prompt %}\\n\\n# \u0110\u1ea7u V\u00e0o V\u0103n B\u1ea3n:\\n{{ prompt }}\\n\\n{% endif %}{% if structure_fields %}# \u0110\u1ecbnh D\u1ea1ng C\u1ea5u Tr\u00fac Ph\u1ea3n H\u1ed3i:\nB\u1ea1n ph\u1ea3i tu\u00e2n theo c\u1ea5u tr\u00fac ph\u1ea3n h\u1ed3i:\n\n{% for field in structure_fields %}{{ field.label }}\\n{% endfor %}\n\nB\u1eb1ng c\u00e1ch tu\u00e2n th\u1ee7 \u0111\u1ecbnh d\u1ea1ng n\u00e0y, ph\u1ea3n h\u1ed3i s\u1ebd duy tr\u00ec t\u00ednh to\u00e0n v\u1eb9n v\u1ec1 m\u1eb7t ng\u00f4n ng\u1eef \u0111\u1ed3ng th\u1eddi t\u0103ng c\u01b0\u1eddng t\u00ednh chuy\u00ean nghi\u1ec7p, c\u1ea5u tr\u00fac v\u00e0 s\u1ef1 ph\u00f9 h\u1ee3p v\u1edbi mong \u0111\u1ee3i c\u1ee7a ng\u01b0\u1eddi d\u00f9ng.\n{% endif %}\n</code></pre>"},{"location":"custom_templates/default_template/","title":"Default Templates","text":"<p>Gemma Template uses Jinja2 template.</p> <p>See also: <code>models.Attr</code></p>"},{"location":"custom_templates/default_template/#gemma-fine-tuning-template","title":"Gemma Fine Tuning Template","text":"<pre><code>&lt;start_of_turn&gt;user\n{{ input }}&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n{{ output }}&lt;end_of_turn&gt;\n</code></pre>"},{"location":"custom_templates/default_template/#gemma-prompt-template","title":"Gemma Prompt Template","text":"<pre><code>&lt;start_of_turn&gt;user\n{{ input }}&lt;end_of_turn&gt;\n&lt;start_of_turn&gt;model\n</code></pre>"},{"location":"custom_templates/default_template/#input-template","title":"Input Template","text":"<pre><code>{{ system_prompt }}\n{% if instruction %}\\n{{ instruction }}\\n{% endif %}\n{% if prompt_structure %}{{ prompt_structure }}\\n{% else %}{{ prompt }}\\n{% endif %}\n# Text:\n{{ input }}\n{% if topic_value %}\\nTopics: {{ topic_value }}\\n{% endif %}{% if keyword_value %}Keywords: {{ keyword_value }}\\n{% endif %}\n</code></pre>"},{"location":"custom_templates/default_template/#output-template","title":"Output Template","text":"<pre><code>{% if structure_fields %}{% for field in structure_fields %}## **{{ field.label.custom or field.label.default }}:**\\n{% if field.key == 'title' %}### {% endif%}{{ field.value }}\\n\\n{% endfor %}{% else %}{{ output }}{% endif %}\n</code></pre>"},{"location":"custom_templates/default_template/#instruction-template","title":"Instruction Template","text":"<pre><code># Role:\nYou are a highly skilled professional content writer, linguistic analyst, and multilingual expert specializing in structured writing and advanced text processing.\n\n# Task:\nYour primary objectives are:\n1. Simplification: Rewrite the input text or document to ensure it is accessible and easy to understand for a general audience while preserving the original meaning and essential details.\n2. Lexical and Grammatical Analysis: Analyze and refine vocabulary and grammar using unigrams (single words), bigrams (two words), and trigrams (three words) to enhance readability and depth.\n3. Structure and Organization: Ensure your response adheres strictly to the prescribed structure format.\n4. Language Consistency: Respond in the same language as the input text unless explicitly directed otherwise.\n\n# Additional Guidelines:\n1. Provide a rewritten, enhanced version of the input text, ensuring professionalism, clarity, and improved structure.\n2. Focus on multilingual proficiency, using complex vocabulary, grammar to improve your responses.\n3. Preserve the context and cultural nuances of the original text when rewriting.\n\n# Text Analysis:\nExample 1: Unigrams (single words){% for word in unigrams %}\\n{{ word }} =&gt; {{ language }}{% endfor %}\nText Analysis 3: These are common {{ language }} words, indicating the text is in {{ language }}.\n\nExample 2: Bigrams (two words){% for word in bigrams %}\\n{{ word }} =&gt; {{ language }}{% endfor %}\nText Analysis 2: Frequent bigrams in {{ language }} confirm the language context.\n\nExample 3: Trigrams (three words){% for word in trigrams %}\\n{{ word }} =&gt; {{ language }}{% endfor %}\nText Analysis 3: Trigrams further validate the linguistic analysis and the necessity to respond in {{ language }}.\n\n# Conclusion of Text Analysis:\nThe linguistic analysis confirms the text is predominantly in {{ language }}. Consequently, the response should be structured and written in {{ language }} to align with the original text and context.\n</code></pre>"},{"location":"custom_templates/default_template/#prompt-template","title":"Prompt Template","text":"<pre><code>{% if prompt %}\\n\\n# Input Text:\\n{{ prompt }}\\n\\n{% endif %}{% if structure_fields %}# Response Structure Format:\nYou must follow the response structure:\n\n{% for field in structure_fields %}{{ field.label }}\\n{% endfor %}\nBy adhering to this format, the response will maintain linguistic integrity while enhancing professionalism, structure and alignment with user expectations.\\n\n{% endif %}\n</code></pre>"}]}